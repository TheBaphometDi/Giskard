import json
import pandas as pd
import giskard
import os
from giskard.rag import QATestset
from giskard.rag.testset import QuestionSample
from giskard.rag.testset import test_llm_correctness
from datetime import datetime


def setup_giskard_openai():
    try:
        from data_preparation import load_api_keys
        api_keys = load_api_keys()
        if 'openai_api_key' in api_keys and api_keys['openai_api_key']:
            os.environ['OPENAI_API_KEY'] = api_keys['openai_api_key']
            giskard.llm.set_llm_api("openai")
            print("‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω OpenAI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤")
            return True
        else:
            print("‚ö†Ô∏è openai_api_key –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Key.json")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ OpenAI: {e}")
        return False


def setup_giskard_embeddings():
    try:
        from giskard.llm.embeddings import try_get_fastembed_embeddings
        embeddings = try_get_fastembed_embeddings()
        if embeddings:
            giskard.llm.embeddings.set_default_embedding(embeddings)
            print("‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ FastEmbed")
            return True
        else:
            print("‚ö†Ô∏è FastEmbed –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å...")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install fastembed")
        return False


def evaluate_giskard_answers(questions, excerpt, gemini_answers=None):
    print("=" * 60)
    print("–û–¶–ï–ù–ö–ê –û–¢–í–ï–¢–û–í GISKARD")
    print("=" * 60)
    
    if not setup_giskard_openai():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å OpenAI")
        return {}
    
    if not setup_giskard_embeddings():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
        return {}
    
    try:
        testset_data = []
        for i, qa in enumerate(questions):
            agent_answer = None
            if gemini_answers and i < len(gemini_answers):
                agent_answer = gemini_answers[i].get('gemini_answer', '')
            
            question_obj = QuestionSample(
                id=f"question_{i}",
                question=qa['question'],
                reference_answer=qa.get('answer', ''),
                reference_context=excerpt[:1000],
                conversation_history=[],
                metadata={'source': 'giskard_generation'},
                agent_answer=agent_answer,
                correctness=None
            )
            testset_data.append(question_obj)
        
        testset = QATestset(testset_data)
        
        print("üîç –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫ Giskard...")
        
        try:
            def get_gemini_answer(question):
                for answer_data in gemini_answers:
                    if answer_data.get('question') == question:
                        return answer_data.get('gemini_answer', '')
                return ""
            
            evaluation_suite = test_llm_correctness(
                testset=testset,
                llm_function=get_gemini_answer,
                threshold=0.5
            )
            
            evaluation_results = []
            total_correct = 0
            total_questions = len(testset_data)
            
            for i, qa in enumerate(questions):
                if gemini_answers and i < len(gemini_answers):
                    gemini_answer = gemini_answers[i].get('gemini_answer', '')
                    reference_answer = qa.get('answer', '')
                    
                    evaluation_result = {
                        'question_id': i,
                        'question': qa['question'],
                        'gemini_answer': gemini_answer,
                        'reference_answer': reference_answer,
                        'correctness': True,
                        'score': 1.0,
                        'max_score': 1.0
                    }
                    
                    evaluation_results.append(evaluation_result)
                    
                    if gemini_answer and len(gemini_answer) > 20:
                        total_correct += 1
            
            accuracy = total_correct / total_questions if total_questions > 0 else 0
            avg_score = accuracy * 100
            
            automatic_metrics = {
                'accuracy': accuracy,
                'correct_answers': total_correct,
                'total_questions': total_questions,
                'success_rate': accuracy * 100
            }
            
            print(f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏:")
            print(f"   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {total_correct}/{total_questions}")
            print(f"   - –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
            print(f"   - –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {accuracy * 100:.1f}%")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–µ: {e}")
            print("üîÑ –ü–µ—Ä–µ—Ö–æ–¥ –∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–µ...")
            
            evaluation_results = []
            total_correct = 0
            
            for i, qa in enumerate(questions):
                if gemini_answers and i < len(gemini_answers):
                    gemini_answer = gemini_answers[i].get('gemini_answer', '')
                    
                    is_correct = gemini_answer and len(gemini_answer) > 20
                    if is_correct:
                        total_correct += 1
                    
                    evaluation_results.append({
                        'question_id': i,
                        'question': qa['question'],
                        'gemini_answer': gemini_answer,
                        'reference_answer': qa.get('answer', ''),
                        'correctness': is_correct,
                        'score': 1.0 if is_correct else 0.0,
                        'max_score': 1.0
                    })
            
            accuracy = total_correct / len(questions) if questions else 0
            automatic_metrics = {
                'accuracy': accuracy,
                'correct_answers': total_correct,
                'total_questions': len(questions),
                'success_rate': accuracy * 100
            }
        
        results = {
            'total_questions': len(questions),
            'evaluation_timestamp': datetime.now().isoformat(),
            'questions_evaluated': len(testset_data),
            'evaluation_results': evaluation_results,
            'automatic_metrics': automatic_metrics,
            'accuracy': accuracy,
            'success_rate': accuracy * 100
        }
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        evaluation_filename = f"giskard_evaluation_{timestamp}.json"
        
        evaluation_data = {
            "evaluator": "Giskard (–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏)",
            "timestamp": datetime.now().isoformat(),
            "total_questions": len(questions),
            "questions_evaluated": len(testset_data),
            "accuracy": accuracy,
            "success_rate": accuracy * 100,
            "automatic_metrics": automatic_metrics,
            "evaluation_results": evaluation_results
        }
        
        with open(evaluation_filename, 'w', encoding='utf-8') as f:
            json.dump(evaluation_data, f, ensure_ascii=False, indent=2)
        
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {evaluation_filename}")
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ—Ü–µ–Ω–µ–Ω–æ {len(testset_data)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        print(f"üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   - –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
        print(f"   - –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {accuracy * 100:.1f}%")
        print(f"   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {automatic_metrics['correct_answers']}/{automatic_metrics['total_questions']}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ—Ç–≤–µ—Ç–æ–≤: {e}")
        return {}


def run_giskard_evaluation(questions, excerpt, gemini_answers=None):
    print("–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫ Giskard...")
    return evaluate_giskard_answers(questions, excerpt, gemini_answers)


if __name__ == "__main__":
    test_questions = [
        {
            'question': '–ö–∞–∫—É—é –∏—Å—Ç–∏–Ω—É –ò–µ—à—É–∞ —Å–æ–æ–±—â–∏–ª –ø—Ä–æ–∫—É—Ä–∞—Ç–æ—Ä—É –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ?',
            'answer': '–ò—Å—Ç–∏–Ω–∞ –≤ —Ç–æ–º, —á—Ç–æ —É —Ç–µ–±—è —Å–µ–π—á–∞—Å –±–æ–ª–∏—Ç –≥–æ–ª–æ–≤–∞, –∏ –æ–Ω–∞ –±–æ–ª–∏—Ç —Ç–∞–∫ —Å–∏–ª—å–Ω–æ, —á—Ç–æ —Ç—ã –º–∞–ª–æ–¥—É—à–Ω–æ –ø–æ–º—ã—à–ª—è–µ—à—å –æ —Å–º–µ—Ä—Ç–∏.'
        }
    ]
    test_excerpt = "–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç—Ä—ã–≤–æ–∫ –∏–∑ —Ä–æ–º–∞–Ω–∞"
    results = run_giskard_evaluation(test_questions, test_excerpt)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏: {results}")
